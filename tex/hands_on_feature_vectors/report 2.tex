%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Report R6b}
%
The report R6 (due on \textbf{Dec 4, Sunday 8.30 PM}) focuses on the characterization of the feature vector extraction and the associated classification model. We expect you to:
%
\begin{itemize}
    \item (H6a) \textbf{Characterize a classification model of your choice on the ESC-50 audio dataset, provide chosen performance metrics and detail the validation method you used. Briefly justify your choices.}
    \begin{itemize}
        \item The classification model has to be different from the provided KNN such that you reproduce the analyzes given in H6a\_audio.ipynb (have a look here :\\ \url{https://scikit-learn.org/stable/supervised\_learning.html#supervised-learning}).
        \item The metrics can be the accuracy and confusion matrix provided in H6a, but can also be other ones as long as you justify their relevance.
        \item The validation method is the way you split the dataset between training and validation.
        \item You must specify if you considered normalization of the feature vectors and if you introduced data augmentation (if so, which ones and why?)
    \end{itemize}
    In short, we ask a paragraph explaining why you chose your model, the used metrics, and validation methods, then one figure with its performances on the validation set. We also ask a figure showing the influence of potential hyperparameters of your model and a discussion on what you observe from it. You won't be evaluated on the performances of the chosen classification model, we are only interested in the quality of your analysis.
    % \item (H6a) \textbf{Study the model robustness to transformations of the feature vectors (scaling, AWGN, etc).}
    % We ask a separate figure for each single transformation, with the data$\_$augmentation$\_$factor you used (i.e. the number of transformations of the same sound you considered for creating the new augmented dataset) as well as if the transformation was deterministic or random, and the associated transformation parameter (e.g. data$\_$augmentation factor of 3, random scaling with maximum 5x bigger or smaller amplitude) . We ask, attached to each figure, a brief discussion on how the classification performances evolve with this transformation. We expect you to do so \textbf{at least for the scaling and AWGN transformations}, but you can do more if desired.
    \item (H6b) \textbf{Evaluate the computational complexity of the feature extraction pipeline on the MCU. Which transformation requires the most computations ? Evaluate the number of cycles each step of requires, steps are specified in the source code \emph{spectrogram.c}.} \\
The feature vector computation simply consists in a chain of well-known mathematical operations with given computational complexity. We ask you to compute the overall complexity when putting it all together.
\item (H6a+H6b) \textbf{Observe and discuss quantitatively the difference observed between melspectrograms:}
\begin{enumerate}
    \item of the original dataset
    \item acquired via a jack cable on the MCU
    \item acquired via the microphone on the MCU.
   \end{enumerate}
   %
     Use \textbf{a few} representative samples of the dataset to conduct your experiments.
       We ask, for each sample, a (1,3) subplot showing the melspectrograms for cases 1,2,3 from left to right. Please make it clear with titles or captions in your figures.
    \item (H6a+H6b) \textbf{Demonstrate the performance of your classification model on feature vectors acquired with the three methods mentioned above.}
    The performance on the original dataset has been asked in the first question. You can thus just make the same analysis on acquired signals, with the few samples of your choice. We still ask at least 3 sounds from each of the 5 classes (crackling fire, chirping bird, chainsaw, helicopter and handsaw) in order to see something.
    \item (H6a+H6b) \textbf{Enhance the performance of your classification model exploiting memory on a full audio signal of 5s.}
    We ask you to exploit the memory effect of consecutive feature vectors coming from the same class to enhance your prediction. You are free to choose any combination of these feature vectors discussed in \emph{H6a\_trust\_and\_memory.ipynb}. Compare your prediction performances with the ones made on single feature vectors. We ask at least one sound from each of the 5 classes (crackling fire, chirping bird, chainsaw, helicopter and handsaw).
\end{itemize}
