{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"Machine learning tools\"\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    ")\n",
    "from classification.utils.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions to select, read and play the dataset sounds are provided in ``classification/utils/audio_student.py``. <br>\n",
    "\n",
    "As for the H1, you will have to fill some short pieces of code, as well as answer some questions. We already created cells for you to answer the questions to ensure you don't forget it ;). <br>\n",
    "You will find the zones to be briefly filled  with a ``### TO COMPLETE`` in the cells below.\n",
    "\n",
    "<font size=6 color=#009999> 2. Training and Evaluating models on audio signals [~1h30-2h] </font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only keep 5 class for this notebook:\n",
    "- birds\n",
    "- chainsaw\n",
    "- fire\n",
    "- handsaw\n",
    "- helicopter\n",
    "\n",
    "The classes used in the contest will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.remove_class(\"background\")\n",
    "dataset.remove_class(\"fireworks\")\n",
    "dataset.remove_class(\"gunshot\")\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "fm_dir = \"data/feature_matrices/\"  # where to save the features matrices\n",
    "model_dir = \"data/models/\"  # where to save the models\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In H1, it was not made explicit what we choose as input for the classification model, a.k.a. ``feature vector`` (it was shown in the illustration). <br>\n",
    "The objective is, on the transmitter side, to compute a feature vector containing enough information about the audio signal we want to classify, but not too much in order to limit the data which has to be transmitted wirelessly. This is why in H1 we implemented the ``Hz2Mel`` conversion: a very simple compression of the frequency content. <br>\n",
    "The feature vector we will use here simply consists in taking the first 20 columns of the melspectrogram, corresponding to ~1s, then reshaping it as a vector. This means each feature vector contains ``400`` coefficients, with 20 columns of 20 mels each.  <br>\n",
    "\n",
    "Once the feature vector has been recovered on the receiver side, we can apply any computation on it to guess the right class this sound belongs to. Today, we will simply reuse the simple KNN and LDA classifiers and look at what we already get. \n",
    "\n",
    "<font size=3 color=#FF0000> Important :</font> <br>\n",
    "The analyses that follow are given as food for thoughts. They are not given as step by step improvements of the classifier.\n",
    "\n",
    "<font size=5 color=#009999> 2.1. Creation of the dataset </font> <br>\n",
    "\n",
    "``Feature_vector_DS`` is a class defined in ``classification/utils/audio_student.py``. <br>\n",
    "The functions ``__len__`` and ``__getitem__`` are implemented, meaning you can call :\n",
    "- ``len(myds)`` to get the number of sounds in it.\n",
    "- ``myds[classname,j]`` to get the melspectrogram of the ``j``-th sound from class ``classname``. <br>\n",
    "\n",
    "Two other useful functions are provided:\n",
    "- ``get_audiosignal`` returning the temporal audiosignal at the specified index.\n",
    "- ``display`` playing the sound and showing the associated mel-spectrogram at the specified index.\n",
    "\n",
    "<font size=3 color=#FF0000> Important :</font> <br>\n",
    "Before being able to run the cells below, you will have to reuse your functions from H1 to fill the missing lines in ``audio_student.py`` at ``###TO COMPLETE`` locations.\n",
    "\n",
    "Moreover, you have to restart your python kernel for any change to those imported files to be taken into account. This can be done by pressing 》which stops the kernel and tries to run each cell sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\n",
    "\"Creation of the dataset\"\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, step=np.inf)\n",
    "# myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, step=40)\n",
    "# myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, step=20)\n",
    "# myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, step=1)\n",
    "\"Some attributes...\"\n",
    "myds.nmel\n",
    "myds.duration\n",
    "myds.sr\n",
    "myds.data_aug\n",
    "myds.ncol\n",
    "\n",
    "\n",
    "idx = 0\n",
    "myds.display([\"fire\", idx], show_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "The magenta boxes shown in the graph shows the part of the spectrogram that will be actually used as feature.\n",
    "\n",
    "- Now, in the Feature_vectore_DS intialization, change the step value to 40, 20 and 1. How does this impact the dataset that will be generated?\n",
    "- Analyze the pros and cons of each value.\n",
    "- Where can you do your train-test split in each case?\n",
    "\n",
    "We have more datasets generated as we go closer to one for the same time period, but given a certain rate, the datasets are merging together and overlapping. When theyre not overlapping we have a smaller dataset cause less windows and no redundancy, the smaller dataset also means its faster to train. But by not selecting the whole time frame we might miss important features.\n",
    "On the otherhand, for faster steps with overlapping windows, we have larger dataset and a lot redundancy, we are sure to not miss any important features. Training might be longer and become predictable, it will memorize patterns rather than trying to detect them effectively.\n",
    "\n",
    "Where to do the train-test split ?\n",
    "Important because risk of data leakage : part of the test set contains information identical to the train set. So it will just have artificial performances as it will be tested on data that it has already seen.\n",
    "\n",
    "So in cases of possible overlapping windows you should do the splitting before creating the windows, otherwise you can do it after and assume you wont have data leakage.\n",
    "\n",
    "\n",
    "Set step back to np.inf for the rest of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the questions above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "X, y = myds.get_feature_vectors()\n",
    "\n",
    "np.save(fm_dir + \"feature_matrix_2D.npy\", X)\n",
    "np.save(fm_dir + \"labels.npy\", y)\n",
    "\n",
    "# X = np.load(fm_dir+\"feature_matrix_2D.npy\")\n",
    "# y = np.load(fm_dir+\"labels.npy\")\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X.shape}\")\n",
    "print(f\"Number of labels : {len(y)}\")\n",
    "\n",
    "print(\n",
    "    \"Remember the convention shown for the toy example, the feature vectors are arranged on the rows.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that ``feature_matrix_2D.npy`` has been saved in ``data/feature_matrices/`` and can now be loaded instead of recomputing it at every run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.2. First audio classification, metrics and dataset splitting </font> <br>\n",
    "\n",
    "For now we have only prepared the dataset, it remains to feed it to the classifiers. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "K = 6  # Number of neighbours for the KNN\n",
    "model_knn = KNeighborsClassifier(\n",
    "    n_neighbors=K, weights=\"distance\", algorithm=\"auto\", metric=\"minkowski\"\n",
    ")  # We explicitly write the default parameters of this KNN classifier once so that you know they exist and can be changed\n",
    "\n",
    "model_lda = LDA(\n",
    "    solver=\"svd\",\n",
    "    shrinkage=None,\n",
    "    priors=None,\n",
    "    n_components=None,\n",
    "    store_covariance=False,\n",
    "    tol=0.0001,\n",
    "    covariance_estimator=None,\n",
    ")  # We explicitly write the default parameters of this LDA classifier once so that you know they exist and can be changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the toy example, we keep the ``accuracy`` as metric and the ``confusion matrix`` as visualization. <br>\n",
    "\n",
    "Note that here we are not especially interested in a model selection hence we only split the dataset in training and testing parts but we don't split the training set in learning/validation parts. The models are trained on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\"Shuffle then split the dataset into training and testing subsets\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y\n",
    ")  # random_state=1\n",
    "print(f\"Shape of the training matrix : {X_train.shape}\")\n",
    "print(f\"Number of training labels : {len(y_train)}\")\n",
    "\n",
    "model_knn.fit(X_train, y_train)\n",
    "model_lda.fit(X_train, y_train)\n",
    "\n",
    "prediction_knn = model_knn.predict(X_test)\n",
    "prediction_lda = model_lda.predict(X_test)\n",
    "accuracy_knn = accuracy(prediction_knn, y_test)\n",
    "accuracy_lda = accuracy(prediction_lda, y_test)\n",
    "\n",
    "print(f\"Accuracy of KNN with fixed train/validation sets : {100 * accuracy_knn:.1f}%\")\n",
    "show_confusion_matrix(prediction_knn, y_test, classnames)\n",
    "print(f\"Accuracy of LDA with fixed train/validation sets : {100 * accuracy_lda:.1f}%\")\n",
    "show_confusion_matrix(prediction_lda, y_test, classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**: \n",
    "- What would be the expected accuracy if the label predictions were picked at random?\n",
    "- What do you observe in this confusion matrix? Run again the cell above, i.e., Reapply the ``train_test_split`` and tell if your observations are robust.\n",
    "\n",
    "If they are picked at random then the accuracy will only depend on the number of classes and be 1/(number of classes).\n",
    "Our accuracy is far better than the random. Even while rerunning the test and training, we observe the same thing so we see that its pretty robust. Strong diagonal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the ``classname`` and the index ``idx`` to pick feature vectors in the dataset ``myds``, listen to the audio associated to the feature vector, and check if you would have been able to predict the right class by your own. Then compare with the prediction given by your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "idx = 0\n",
    "classname = \"helicopter\"\n",
    "myds.display([classname, idx], show_features=True)\n",
    "thisfv = myds.treat_spec(myds[classname, idx])[0]\n",
    "\n",
    "# this artefact is necessary because the 'predict' function expects a matrix_like input.\n",
    "mat = np.zeros((2, len(thisfv)))\n",
    "mat[0] = thisfv\n",
    "\n",
    "prediction_knn = model_knn.predict(mat)\n",
    "prediction_lda = model_lda.predict(mat)\n",
    "\n",
    "print(\"Class predicted by KNN:\", prediction_knn[0])\n",
    "print(\"Class predicted by LDA:\", prediction_lda[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, when training a model and comparing different settings, there is a risk that we will end up choosing optimal parameters that only render good result on our specific case of training and validation set, but ``do not generalize well for additional data``. This is called ``overfitting on the validation set``. To alleviate this, we can perform ``cross-validation (CV)``. A basic approach named ``K-fold CV`` involves partitioning the dataset in ``K`` \"folds\" (subsets) and repetitvely do the following procedure:\n",
    "\n",
    "- Train the model using `K-1` folds as the training data.\n",
    "- Test the model using the last fold as the validation data.\n",
    "\n",
    "The overall performance on each fold is then averaged to obtain the final performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "accuracy_knn = np.zeros((n_splits,))\n",
    "accuracy_lda = np.zeros((n_splits,))\n",
    "for k, idx in enumerate(kf.split(X_train, y_train)):\n",
    "    (idx_learn, idx_val) = idx\n",
    "    model_knn.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "    prediction_knn = model_knn.predict(X_train[idx_val])\n",
    "    accuracy_knn[k] = accuracy(prediction_knn, y_train[idx_val])\n",
    "\n",
    "    model_lda.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "    prediction_lda = model_lda.predict(X_train[idx_val])\n",
    "    accuracy_lda[k] = accuracy(prediction_lda, y_train[idx_val])\n",
    "\n",
    "print(f\"Mean accuracy of KNN with 5-Fold CV: {100 * accuracy_knn.mean():.1f}%\")\n",
    "print(\n",
    "    f\"Std deviation in accuracy of KNN with 5-Fold CV: {100 * accuracy_knn.std():.1f}%\"\n",
    ")\n",
    "\n",
    "print(f\"Mean accuracy of LDA with 5-Fold CV: {100 * accuracy_lda.mean():.1f}%\")\n",
    "print(\n",
    "    f\"Std deviation in accuracy of LDA with 5-Fold CV: {100 * accuracy_lda.std():.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.3. Scale mismatch and countermeasure </font> <br>\n",
    "\n",
    "In real conditions, you will most probably have a different scale between the feature vectors used for training (in simulation) and the ones you feed in your model to make predictions.\n",
    "This scale mismatch between model training and prediction is difficult to prevent because it depends on multiple factors such as the audio source power, its distance to the microphone, the telecommunication distance. <br>\n",
    "\n",
    "Below, we illustrate the link between the volume of the audio and its distance to the origin of the feature space. At different emission distances, the exact same sound would be heard at a different volume and the associated feature vector would be located at another position in the *feature space*. Eventually, this would result in a completely different classification, which is undesirable.\n",
    "\n",
    "<center> <img src=\"figs/norms.png\" alt=\"\" width=\"350\"/> </center>\n",
    "\n",
    "### Questions:\n",
    "\n",
    "- How could you avoid this dependency on the volume of the sound?\n",
    "- What is represented in the hatched centered area? How would you classify feature vectors in this area?\n",
    "\n",
    "We should use features that are invariant of amplitude as the ampltidue can be mostly determined by the distance and thus the signal power. We could either normalise the feature or log spectogram which will mostly compress the differences in amplitude. Easiest thing is to just normalise by the distance -> creates sphere vector. \n",
    "Closest to the origin so its vector is small and thus we cant characterize it so its unknown and not classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the ``dB_mismatch`` variable here below and observe its effect on the confusion matrix.\n",
    "\n",
    "On which part of the dataset are we computing this confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "dB_mismatch = 0  # Play with this value\n",
    "X_val_scaled = X_train[idx_val] * 10 ** (-dB_mismatch / 20)\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors=10)\n",
    "model_knn.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "prediction_knn = model_knn.predict(X_val_scaled)\n",
    "show_confusion_matrix(prediction_knn, y_train[idx_val], classnames)\n",
    "accuracy_knn = accuracy(prediction_knn, y_train[idx_val])\n",
    "print(f\"Accuracy of KNN: {100 * accuracy_knn:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest countermeasure we can think of is to normalise the feature vector (i.e. unitize its norm) prior to use, both for training and testing. Remember how this normalization could be visualized in ``hands_on_classif1_toy_student.ipynb`` <br>\n",
    "Play again with the ``dB_mismatch`` variable here below and observe its effect on the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "dB_mismatch = 1  # Play with this value\n",
    "\n",
    "X_learn_normalised = X_train[idx_learn] / np.linalg.norm(\n",
    "    X_train[idx_learn], axis=1, keepdims=True\n",
    ")\n",
    "model_knn = KNeighborsClassifier(n_neighbors=10, weights=\"distance\")\n",
    "model_knn.fit(X_learn_normalised, y_train[idx_learn])\n",
    "\n",
    "X_val_scaled = X_train[idx_val] * 10 ** (-dB_mismatch / 20)\n",
    "X_val_normalised = X_val_scaled / np.linalg.norm(X_val_scaled, axis=1, keepdims=True)\n",
    "\n",
    "prediction_knn = model_knn.predict(X_val_normalised)\n",
    "show_confusion_matrix(prediction_knn, y_train[idx_val], classnames)\n",
    "accuracy_knn = accuracy(prediction_knn, y_train[idx_val])\n",
    "print(f\"Accuracy of KNN: {100 * accuracy_knn:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: \n",
    "- What will happen with this normalisation countermeasure when there is no sound around the microphone? Is this desirable? How could you deal with it?\n",
    "\n",
    "Amplify undesired noise since there is no sound, we only have noise and its norm is really close to the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.4. Dimensionality reduction </font> <br>\n",
    "\n",
    "It is sometimes good practice to reduce the dimensionality of a signal in order to get the main components of their distribution. A motivation is that usual norms behave counter-inuitively in high dimension. It also further reduces the memory cost of the feature vector. To reduce the dimensionality, we will use the ``Principal component analysis (PCA)`` proposed by sklearn. See the [associated Wikipedia page](https://en.wikipedia.org/wiki/Principal_component_analysis). Recall: the PCA consists in reducing the dimensionality of data vectors encoded in $\\boldsymbol X \\in \\mathbb R^{d\\times N}$ to only $p \\ll d$ dimensions as\n",
    "\n",
    "$$\n",
    "    \\boldsymbol Y = \\boldsymbol V_p^\\top \\boldsymbol X \\in \\mathbb R^{p\\times N},\n",
    "$$\n",
    "\n",
    "where the SVD of the covariance matrix writes as $\\hat{\\boldsymbol\\Sigma}_{\\boldsymbol X} = \\frac{1}{d} \\boldsymbol{XX}^\\top = \\boldsymbol{U\\Sigma V}^\\top$, and $\\boldsymbol V_p$ is the subselection of the first $p$ columns of $\\boldsymbol V$. \n",
    "\n",
    "For our application, reducing the dimensionality of the data can be helpful for compressing the packet size to be transmitted wirelessly. Indeed, once learned during training, $\\boldsymbol V_p$ can be hardcoded on the transmitter side.\n",
    "\n",
    "Starting with a PCA to 2D for visualization, see how hard it is to separate the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "n = 2  # Number of principal components kept\n",
    "pca = PCA(n_components=n, whiten=True)\n",
    "X_learn_reduced = pca.fit_transform(X_train[idx_learn])\n",
    "X_val_reduced = pca.transform(X_train[idx_val])\n",
    "\n",
    "print(f\"Shape of the reduced training matrix : {X_learn_reduced.shape}\")\n",
    "\n",
    "y_train_num = np.zeros(y_train.shape)\n",
    "for i, classname in enumerate(classnames):\n",
    "    y_train_num[y_train == classname] = i\n",
    "\n",
    "K = 10\n",
    "model_knn = KNeighborsClassifier(n_neighbors=K)\n",
    "model_knn.fit(X_learn_reduced, y_train_num[idx_learn])\n",
    "prediction_knn = model_knn.predict(X_val_reduced)\n",
    "accuracy_knn = accuracy(prediction_knn, y_train_num[idx_val])\n",
    "\n",
    "model_lda = LDA()\n",
    "model_lda.fit(X_learn_reduced, y_train_num[idx_learn])\n",
    "prediction_lda = model_lda.predict(X_val_reduced)\n",
    "accuracy_lda = accuracy(prediction_lda, y_train_num[idx_val])\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "axs = [fig.add_axes([0.0, 0.0, 0.4, 0.9]), fig.add_axes([0.6, 0.0, 0.4, 0.9])]\n",
    "plot_decision_boundaries(\n",
    "    X_learn_reduced,\n",
    "    y_train_num[idx_learn],\n",
    "    ax=axs[0],\n",
    "    model=model_knn,\n",
    "    legend=classnames,\n",
    "    title=\"KNN\",\n",
    ")\n",
    "plot_decision_boundaries(\n",
    "    X_learn_reduced,\n",
    "    y_train_num[idx_learn],\n",
    "    ax=axs[1],\n",
    "    model=model_lda,\n",
    "    legend=classnames,\n",
    "    title=\"LDA\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: \n",
    "- From the decision boundaries shown here above, can you explain why the ``handsaw`` class is less often chosen than the other classes for the ``KNN`` classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the questions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "n = 5  # Number of principal components kept\n",
    "pca = PCA(n_components=n, whiten=True)\n",
    "X_learn_reduced = pca.fit_transform(X_train[idx_learn])\n",
    "X_val_reduced = pca.transform(X_train[idx_val])\n",
    "\n",
    "print(f\"Shape of the reduced learning matrix : {X_learn_reduced.shape}\")\n",
    "\n",
    "K = 10\n",
    "model_knn = KNeighborsClassifier(n_neighbors=K, weights=\"distance\")\n",
    "model_knn.fit(X_learn_reduced, y_train[idx_learn])\n",
    "prediction_knn = model_knn.predict(X_val_reduced)\n",
    "accuracy_knn = accuracy(prediction_knn, y_train[idx_val])\n",
    "\n",
    "model_lda = LDA()\n",
    "model_lda.fit(X_learn_reduced, y_train[idx_learn])\n",
    "prediction_lda = model_lda.predict(X_val_reduced)\n",
    "accuracy_lda = accuracy(prediction_lda, y_train[idx_val])\n",
    "\n",
    "print(f\"Accuracy of the KNN : {100 * accuracy_knn:.1f}%\")\n",
    "show_confusion_matrix(prediction_knn, y_train[idx_val], classnames)\n",
    "print(f\"Accuracy of the LDA : {100 * accuracy_lda:.1f}%\")\n",
    "show_confusion_matrix(prediction_lda, y_train[idx_val], classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.5. Analysis of the hyperparameters </font> <br>\n",
    "\n",
    "Finally, we can inspect the influence of ``hyperparameters`` as we did for the toy example. <br>\n",
    "Let us start by analyzing the influence of the number of neighbours $K$ in the KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "Ks = np.arange(6, 15, 1)\n",
    "accuracies_knn = np.zeros((len(Ks), n_splits))\n",
    "for i, K in enumerate(Ks):\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=K, weights=\"distance\")\n",
    "    for k, idx in enumerate(kf.split(X_train, y_train)):\n",
    "        (idx_learn, idx_val) = idx\n",
    "        model_knn.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "        prediction_knn = model_knn.predict(X_train[idx_val])\n",
    "        accuracies_knn[i, k] = accuracy(prediction_knn, y_train[idx_val])\n",
    "means_knn = accuracies_knn.mean(axis=1)\n",
    "stds_knn = accuracies_knn.std(axis=1)\n",
    "\n",
    "\"Plot\"\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(Ks, means_knn, \".-b\", label=\"KNN\")\n",
    "plt.fill_between(Ks, means_knn - stds_knn, means_knn + stds_knn, alpha=0.2, color=\"b\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider both ``K`` and the number of principal components ``n``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "Ks = np.arange(1, 10)\n",
    "n_comps = np.arange(2, 15)  # number of principal components kept for the PCA\n",
    "accuracies_knn = np.zeros((len(Ks), len(n_comps)))\n",
    "accuracies_lda = np.zeros(len(n_comps))\n",
    "\n",
    "for j, n in enumerate(n_comps):\n",
    "    for idx_learn, idx_val in kf.split(X_train, y_train):\n",
    "        pca = PCA(n_components=n, whiten=True)\n",
    "        X_learn_reduced = pca.fit_transform(X_train[idx_learn])\n",
    "        X_val_reduced = pca.transform(X_train[idx_val])\n",
    "        for i, K in enumerate(Ks):\n",
    "            model_knn = KNeighborsClassifier(n_neighbors=K)\n",
    "            model_knn.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "            prediction_knn = model_knn.predict(X_train[idx_val])\n",
    "            accuracies_knn[i, j] += accuracy(prediction_knn, y_train[idx_val])\n",
    "\n",
    "        model_lda = LDA()\n",
    "        model_lda.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "        prediction_lda = model_lda.predict(X_train[idx_val])\n",
    "        accuracies_lda[j] += accuracy(prediction_lda, y_train[idx_val])\n",
    "\n",
    "accuracies_knn /= n_splits\n",
    "accuracies_lda /= n_splits\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "axs = [fig.add_axes([0.0, 0.0, 0.4, 0.9]), fig.add_axes([0.6, 0.0, 0.4, 0.9])]\n",
    "\n",
    "im0 = axs[0].imshow(100 * accuracies_knn, cmap=\"jet\", origin=\"lower\")\n",
    "cbar = fig.colorbar(im0, ax=axs[0])\n",
    "cbar.set_label(\"Accuracy (%)\")\n",
    "axs[0].set_xlabel(\"n_PCA\")\n",
    "axs[0].set_ylabel(\"K\")\n",
    "axs[0].set_xticks(list(np.arange(len(n_comps))))\n",
    "axs[0].set_xticklabels(list(n_comps))\n",
    "axs[0].set_yticks(list(np.arange(len(Ks))))\n",
    "axs[0].set_yticklabels(list(Ks))\n",
    "axs[0].set_title(\"KNN\")\n",
    "\n",
    "axs[1].plot(accuracies_lda * 100)\n",
    "axs[1].set_xlabel(\"n_PCA\")\n",
    "axs[1].set_ylabel(\"Accuracy (%)\")\n",
    "axs[1].set_title(\"LDA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: \n",
    "- Do you observe some dependency of the accuracy on these parameters? If so, which one(s)? If not, discuss what it tells about the considered model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the question above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.6. Augmenting the data </font> <br>\n",
    "\n",
    "In order to make our classifier more robust to some common transformations of the audio signal such as ``time shift``, ``AWGN``, or a ``transfer function``, an idea consists in feeding the classifier with such transformations. A popular approach is to create new feature vectors based on transformed versions of the sounds from the original dataset, this is called ``data augmentation``. Data augmentation is also often used when there is few data to train a model. <br>\n",
    "\n",
    "The functions to augment your data are written in ``utils/audio_student.py``, we already implemented ``time_shift``, ``echo`` and ``spectro_aug_timefreq_masking`` for you. Try to implement ``scaling``, ``add_noise``, ``filter``, ``add_bg`` and even more data augmentation techniques if you want, and check their working in the cell below. <br>\n",
    "\n",
    "<u>Tip</u>: to avoid restarting the notebook kernel for each modification, you can temporarily insert the ``AudioUtil`` class in a new cell and make your tests until it is working as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "myds.data_aug = None  # Ensure\n",
    "\n",
    "cls_index = [\"birds\", 4]\n",
    "\n",
    "sound = dataset.__getitem__(cls_index)\n",
    "name = dataset.__getname__(cls_index)\n",
    "audio = AudioUtil.open(sound)\n",
    "\n",
    "AudioUtil.play(audio)\n",
    "audio2 = AudioUtil.resample(audio, 11025)\n",
    "audio2 = AudioUtil.pad_trunc(audio2, 5000)\n",
    "\n",
    "audio3 = AudioUtil.scaling(audio2)\n",
    "audio4 = AudioUtil.add_noise(audio2, sigma=1e-2)\n",
    "audio5 = AudioUtil.echo(audio2, 3)\n",
    "audio6 = AudioUtil.add_bg(audio2, dataset)\n",
    "\n",
    "melspec = AudioUtil.melspectrogram(audio2, fs2=11025)\n",
    "melspec2 = AudioUtil.spectro_aug_timefreq_masking(melspec, max_mask_pct=0.1)\n",
    "\n",
    "\"Plot\"\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "ax1 = fig.add_axes([0.05, 0.05, 0.28, 0.9])\n",
    "ax2 = fig.add_axes([0.38, 0.05, 0.28, 0.9])\n",
    "ax3 = fig.add_axes([0.7, 0.05, 0.28, 0.9])\n",
    "\n",
    "ax1.plot(audio2[0], label=\"Original\")\n",
    "ax1.plot(audio3[0] + 1, label=\"Rescaled\")\n",
    "ax1.plot(audio4[0] + 2, label=\"Noisy\")\n",
    "ax1.plot(audio5[0] + 3, label=\"With echos\")\n",
    "ax1.plot(audio6[0] + 4, label=\"With background sound\")\n",
    "ax1.legend()\n",
    "\n",
    "plot_specgram(melspec, ax2, is_mel=True, title=name, tf=len(audio2[0]) / audio2[1])\n",
    "ax2.set_title(\"Melspectrogram\")\n",
    "plot_specgram(melspec2, ax3, is_mel=True, title=name, tf=len(audio2[0]) / audio2[1])\n",
    "ax3.set_title(\"Corrupted melspectrogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new augmented dataset and observe if the classification results improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "myds.mod_data_aug([\"add_bg\"])\n",
    "\n",
    "X_aug, y_aug = myds.get_feature_vectors()\n",
    "\n",
    "np.save(fm_dir + \"feature_matrix_2D_aug.npy\", X)\n",
    "np.save(fm_dir + \"labels_aug.npy\", y)\n",
    "\n",
    "# X_aug = np.load(fm_dir+\"feature_matrix_2D_aug.npy\")\n",
    "# y_aug = np.load(fm_dir+\"labels_aug.npy\")\n",
    "\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X_aug.shape}\")\n",
    "print(f\"Number of labels : {len(y_aug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "K = 10  # Number of neighbours\n",
    "model = KNeighborsClassifier(n_neighbors=K)\n",
    "\n",
    "accuracy_aug = np.zeros((n_splits,))\n",
    "for k, idx in enumerate(kf.split(X_aug, y_aug)):\n",
    "    (idx_train, idx_test) = idx\n",
    "    model.fit(X_aug[idx_train], y_aug[idx_train])\n",
    "    prediction_aug = model.predict(X_aug[idx_test])\n",
    "    accuracy_aug[k] = accuracy(prediction_aug, y_aug[idx_test])\n",
    "\n",
    "print(f\"Mean accuracy with 5-Fold CV: {100 * accuracy_aug.mean():.1f}%\")\n",
    "print(f\"Std deviation in accuracy with 5-Fold CV: {100 * accuracy_aug.std():.1f}%\")\n",
    "show_confusion_matrix(prediction_aug, y_aug[idx_test], classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "- Can you see an improvement of the classification result compared to the non augmented dataset? Try to interpret your answer by thinking about the distribution of points in a data space (as with the toy example), what does it imply to augment the data in terms of distribution of points in the data space?\n",
    "- With the ``add_bg`` augmentation technique, where are the additive background signals coming from? It is a good thing?\n",
    "- What transformations are most likely to be realistic in your application? What is the most efficient way to integrate these alterations in your classification task? ``Hint``: it does not require augmenting your data in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the question above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.7. Getting it all together </font> <br>\n",
    "\n",
    "Now that some aspects to be considered during the model training and analysis have been presented, it remains to train and save a final model that will be used for further predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [1] CRÉATION DU DATASET\n",
    "# =============================================================================\n",
    "print(\"Creating dataset...\")\n",
    "# step=51 génère plusieurs feature vectors par audio pour éviter l'overfitting\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, step=51)\n",
    "\n",
    "X, y = myds.get_feature_vectors()\n",
    "\n",
    "print(\n",
    "    f\"Dataset: {X.shape}, {len(classnames)} classes, {X.shape[0] // len(classnames)} samples/class\"\n",
    ")\n",
    "\n",
    "# Split train/test stratifié\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# [2] NORMALISATION L2\n",
    "# =============================================================================\n",
    "print(\"\\nNormalizing...\")\n",
    "X_train_norm = X_train / np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "X_test_norm = X_test / np.linalg.norm(X_test, axis=1, keepdims=True)\n",
    "\n",
    "# =============================================================================\n",
    "# [3] PCA\n",
    "# =============================================================================\n",
    "print(\"Applying PCA...\")\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components, whiten=True)\n",
    "X_train_reduced = pca.fit_transform(X_train_norm)\n",
    "X_test_reduced = pca.transform(X_test_norm)\n",
    "print(\n",
    "    f\"PCA: {X_train.shape[1]} -> {n_components} features ({pca.explained_variance_ratio_.sum():.1%} variance)\"\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# [4] CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CROSS-VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "cv_accuracies = []\n",
    "cv_predictions = None\n",
    "cv_true_labels = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_reduced, y_train)):\n",
    "    model.fit(X_train_reduced[train_idx], y_train[train_idx])\n",
    "    pred = model.predict(X_train_reduced[val_idx])\n",
    "    acc = accuracy(pred, y_train[val_idx])\n",
    "    cv_accuracies.append(acc)\n",
    "\n",
    "    if fold == n_splits - 1:\n",
    "        cv_predictions = pred\n",
    "        cv_true_labels = y_train[val_idx]\n",
    "\n",
    "print(\n",
    "    f\"CV Accuracy: {100 * np.mean(cv_accuracies):.1f}% (+/- {100 * np.std(cv_accuracies):.1f}%)\"\n",
    ")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Validation):\")\n",
    "show_confusion_matrix(cv_predictions, cv_true_labels, classnames)\n",
    "\n",
    "# =============================================================================\n",
    "# [5] ENTRAÎNEMENT FINAL\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL MODEL TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model.fit(X_train_reduced, y_train)\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "pickle.dump(model, open(model_dir + \"random_forest_model.pickle\", \"wb\"))\n",
    "pickle.dump(pca, open(model_dir + \"pca_transform.pickle\", \"wb\"))\n",
    "print(\"Models saved\")\n",
    "\n",
    "# =============================================================================\n",
    "# [6] ÉVALUATION TEST SET\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prediction_test = model.predict(X_test_reduced)\n",
    "accuracy_test = accuracy(prediction_test, y_test)\n",
    "\n",
    "gap = abs(np.mean(cv_accuracies) - accuracy_test)\n",
    "print(f\"Test Accuracy: {100 * accuracy_test:.1f}%\")\n",
    "print(\n",
    "    f\"Gap CV/Test: {100 * gap:.1f}% ({'Good' if gap < 0.05 else 'Acceptable' if gap < 0.10 else 'Poor'})\"\n",
    ")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test):\")\n",
    "show_confusion_matrix(prediction_test, y_test, classnames)\n",
    "\n",
    "print(\"\\nPer-Class Metrics:\")\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_test, prediction_test, labels=classnames, average=None\n",
    ")\n",
    "print(f\"{'Class':<12} {'Prec':>6} {'Rec':>6} {'F1':>6} {'Sup':>5}\")\n",
    "print(\"-\" * 40)\n",
    "for i, cls in enumerate(classnames):\n",
    "    print(\n",
    "        f\"{cls:<12} {precision[i]:>6.2f} {recall[i]:>6.2f} {f1[i]:>6.2f} {int(support[i]):>5}\"\n",
    "    )\n",
    "\n",
    "# =============================================================================\n",
    "# [7] ANALYSE DES HYPERPARAMÈTRES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HYPERPARAMETER ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Impact de n_estimators\n",
    "print(\"\\nAnalyzing n_estimators...\")\n",
    "n_estimators_range = [10, 25, 50, 75, 100, 150, 200, 250, 300]\n",
    "accuracies_n_estimators = []\n",
    "std_n_estimators = []\n",
    "\n",
    "for n_est in n_estimators_range:\n",
    "    model_temp = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=15,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        max_features=\"sqrt\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    cv_acc = []\n",
    "    for train_idx, val_idx in kf.split(X_train_reduced, y_train):\n",
    "        model_temp.fit(X_train_reduced[train_idx], y_train[train_idx])\n",
    "        pred = model_temp.predict(X_train_reduced[val_idx])\n",
    "        cv_acc.append(accuracy(pred, y_train[val_idx]))\n",
    "\n",
    "    accuracies_n_estimators.append(np.mean(cv_acc))\n",
    "    std_n_estimators.append(np.std(cv_acc))\n",
    "\n",
    "# Impact de max_depth\n",
    "print(\"Analyzing max_depth...\")\n",
    "max_depth_range = [5, 10, 15, 20, 25, 30, None]\n",
    "accuracies_max_depth = []\n",
    "std_max_depth = []\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    model_temp = RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=depth,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        max_features=\"sqrt\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    cv_acc = []\n",
    "    for train_idx, val_idx in kf.split(X_train_reduced, y_train):\n",
    "        model_temp.fit(X_train_reduced[train_idx], y_train[train_idx])\n",
    "        pred = model_temp.predict(X_train_reduced[val_idx])\n",
    "        cv_acc.append(accuracy(pred, y_train[val_idx]))\n",
    "\n",
    "    accuracies_max_depth.append(np.mean(cv_acc))\n",
    "    std_max_depth.append(np.std(cv_acc))\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot n_estimators\n",
    "axes[0].plot(\n",
    "    n_estimators_range, accuracies_n_estimators, \"o-\", linewidth=2, markersize=8\n",
    ")\n",
    "axes[0].fill_between(\n",
    "    n_estimators_range,\n",
    "    np.array(accuracies_n_estimators) - np.array(std_n_estimators),\n",
    "    np.array(accuracies_n_estimators) + np.array(std_n_estimators),\n",
    "    alpha=0.2,\n",
    ")\n",
    "axes[0].set_xlabel(\"Number of Estimators\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Cross-Validation Accuracy\", fontsize=12)\n",
    "axes[0].set_title(\"Impact of n_estimators on Model Performance\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim([0.65, 0.85])\n",
    "\n",
    "# Plot max_depth\n",
    "depth_labels = [str(d) if d is not None else \"None\" for d in max_depth_range]\n",
    "axes[1].plot(\n",
    "    range(len(max_depth_range)), accuracies_max_depth, \"o-\", linewidth=2, markersize=8\n",
    ")\n",
    "axes[1].fill_between(\n",
    "    range(len(max_depth_range)),\n",
    "    np.array(accuracies_max_depth) - np.array(std_max_depth),\n",
    "    np.array(accuracies_max_depth) + np.array(std_max_depth),\n",
    "    alpha=0.2,\n",
    ")\n",
    "axes[1].set_xticks(range(len(max_depth_range)))\n",
    "axes[1].set_xticklabels(depth_labels)\n",
    "axes[1].set_xlabel(\"Max Depth\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Cross-Validation Accuracy\", fontsize=12)\n",
    "axes[1].set_title(\"Impact of max_depth on Model Performance\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0.65, 0.85])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('hyperparameter_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f\"Best n_estimators: {n_estimators_range[np.argmax(accuracies_n_estimators)]} ({100 * max(accuracies_n_estimators):.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Best max_depth: {max_depth_range[np.argmax(accuracies_max_depth)]} ({100 * max(accuracies_max_depth):.1f}%)\"\n",
    ")\n",
    "\n",
    "# Grid Search 2D\n",
    "print(\"\\nGrid Search 2D...\")\n",
    "n_est_grid = [1, 2, 5, 10, 25, 50, 100, 150, 200]\n",
    "depth_grid = [10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "accuracy_grid = np.zeros((len(depth_grid), len(n_est_grid)))\n",
    "\n",
    "for i, depth in enumerate(depth_grid):\n",
    "    for j, n_est in enumerate(n_est_grid):\n",
    "        model_temp = RandomForestClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        cv_acc = []\n",
    "        for train_idx, val_idx in kf.split(X_train_reduced, y_train):\n",
    "            model_temp.fit(X_train_reduced[train_idx], y_train[train_idx])\n",
    "            pred = model_temp.predict(X_train_reduced[val_idx])\n",
    "            cv_acc.append(accuracy(pred, y_train[val_idx]))\n",
    "        accuracy_grid[i, j] = np.mean(cv_acc)\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "im = plt.imshow(accuracy_grid * 100, cmap=\"RdYlGn\", aspect=\"auto\", vmin=70, vmax=85)\n",
    "plt.colorbar(im, label=\"Accuracy (%)\")\n",
    "plt.xticks(range(len(n_est_grid)), n_est_grid)\n",
    "plt.yticks(range(len(depth_grid)), depth_grid)\n",
    "plt.xlabel(\"Number of Estimators\")\n",
    "plt.ylabel(\"Max Depth\")\n",
    "plt.title(\"Random Forest Hyperparameter Grid Search\")\n",
    "\n",
    "# Ajouter les valeurs dans les cellules\n",
    "for i in range(len(depth_grid)):\n",
    "    for j in range(len(n_est_grid)):\n",
    "        text = plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{accuracy_grid[i, j] * 100:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"black\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('hyperparameter_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Meilleure configuration\n",
    "best_idx = np.unravel_index(accuracy_grid.argmax(), accuracy_grid.shape)\n",
    "best_depth = depth_grid[best_idx[0]]\n",
    "best_n_est = n_est_grid[best_idx[1]]\n",
    "best_acc = accuracy_grid[best_idx[0], best_idx[1]]\n",
    "\n",
    "print(\n",
    "    f\"Optimal configuration: n_estimators={best_n_est}, max_depth={best_depth} -> {100 * best_acc:.1f}%\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, step=np.inf)\n",
    "\n",
    "print(\"Building feature matrix (this may take a while)...\")\n",
    "X, y = myds.get_feature_vectors()\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(f\"Full feature matrix shape: {X.shape}\")\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=0\n",
    ")\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# [2] (optional) Data normalization\n",
    "do_normalize = True\n",
    "if do_normalize:\n",
    "    # avoid division by zero\n",
    "    norms = np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    X_train = X_train / norms\n",
    "\n",
    "    norms_test = np.linalg.norm(X_test, axis=1, keepdims=True)\n",
    "    norms_test[norms_test == 0] = 1.0\n",
    "    X_test = X_test / norms_test\n",
    "\n",
    "# [3] (optional) dimensionality reduction (PCA)\n",
    "use_pca = True\n",
    "pca = None\n",
    "if use_pca:\n",
    "    # Choose a reasonable number of components (not larger than original dim)\n",
    "    n_components = min(50, X_train.shape[1])\n",
    "    pca = PCA(n_components=n_components, whiten=True)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    print(f\"PCA applied, components={n_components}, transformed shape: {X_train.shape}\")\n",
    "\n",
    "# [4] Model training and selection.\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# [6] Evaluate the model on the test set\n",
    "prediction = model.predict(X_test)\n",
    "acc = accuracy(prediction, y_test)\n",
    "print(f\"Test accuracy: {100 * acc:.2f}%\")\n",
    "show_confusion_matrix(prediction, y_test, classnames)\n",
    "\n",
    "# [5] Save the trained model, eventually the pca.\n",
    "import pickle\n",
    "\n",
    "filename = \"knn_model.pickle\"\n",
    "pickle.dump(model, open(model_dir + filename, \"wb\"))\n",
    "if pca is not None:\n",
    "    pickle.dump(pca, open(model_dir + \"pca.pickle\", \"wb\"))\n",
    "\n",
    "print(f\"Model and optional PCA saved to {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.8. Debriefing </font> <br>\n",
    "**Questions** : \n",
    "\n",
    "1) from what we have done in this notebook, can you already identify some weaknesses in the feature vector computation and classification pipeline? You can make a list here below, and eventually write some short ideas for improvement. This will help you later :)\n",
    "2) Do you remember what is the time duration of a feature vector? What happens if no sound is produced during the acquisition time of a feature vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the question above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lelec210x (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
