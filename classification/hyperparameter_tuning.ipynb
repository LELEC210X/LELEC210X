{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from classification.datasets import Dataset_augmented\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    ")\n",
    "from classification.utils.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters other than those of the model\n",
    "Nft = 512 # number of samples in the Fourier transform\n",
    "nmel = 20 # number of mel bands\n",
    "pca = int(math.ceil(11025/Nft) * nmel / 2) # number of components in PCA\n",
    "# threshold = 0.05 # threshold under which we discard the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset and splitting it into training and test sets\n",
    "\n",
    "# Load the dataset\n",
    "dataset = Dataset_augmented()\n",
    "classnames = dataset.list_classes() #['chainsaw', 'fire', 'fireworks', 'gun']\n",
    "\n",
    "# Splitting the dataset by hand, we will use a 70/30 split\n",
    "# we have 280 audio files for each class except for gun which has 272\n",
    "# so we will generate 196 random indexes for each class (except gun) and use them as the training set\n",
    "\n",
    "random_indexes = [[], [], [], []]\n",
    "random_indexes[0] = np.random.choice(280, 196, replace=False)\n",
    "random_indexes[1] = np.random.choice(280, 196, replace=False)\n",
    "random_indexes[2] = np.random.choice(280, 196, replace=False)\n",
    "random_indexes[3] = np.random.choice(272, 190, replace=False)\n",
    "\n",
    "# we will use the remaining indexes as the test set\n",
    "test_indexes = [[], [], [], []]\n",
    "test_indexes[0] = np.setdiff1d(np.arange(280), random_indexes[0])\n",
    "test_indexes[1] = np.setdiff1d(np.arange(280), random_indexes[1])\n",
    "test_indexes[2] = np.setdiff1d(np.arange(280), random_indexes[2])\n",
    "test_indexes[3] = np.setdiff1d(np.arange(272), random_indexes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mel spectrogram of each audio file and saving in a folder\n",
    "folder_path = \"src/classification/datasets/melspectrograms/\"\n",
    "number_audio_files = [280, 280, 280, 272]\n",
    "n_win_files = np.zeros(280*3 + 272)\n",
    "\n",
    "for class_index in range (len(classnames)):\n",
    "    for audio_index in range(number_audio_files[class_index]):\n",
    "        current_sound = dataset[classnames[class_index], audio_index]\n",
    "        current_audio = AudioUtil.open(current_sound)\n",
    "        current_audio = AudioUtil.resample(current_audio, 11025)\n",
    "        \n",
    "        # we will split the audio into 1 second window, and compute the mel spectrogram of each clip\n",
    "        n_win = (len(current_audio[0]) // 11025) + 1\n",
    "        n_win_files[class_index * 280 + audio_index] = n_win\n",
    "        for window in range(n_win):\n",
    "            sub_aud = (current_audio[0][window * 11025 :], current_audio[1])\n",
    "            sub_aud = AudioUtil.pad_trunc(sub_aud, 950)\n",
    "            sgram = AudioUtil.melspectrogram(sub_aud, Nmel=nmel, Nft=Nft)\n",
    "            ncol = int(11025 / Nft)\n",
    "            sgram = sgram[:, :ncol]\n",
    "            fv = sgram.reshape(-1)\n",
    "            # saving the mel spectrogram in .npy format\n",
    "            np.save(folder_path + classnames[class_index] + str(audio_index) + \"_\" + str(window) + \".npy\", fv)\n",
    "\n",
    "fv_len = len(fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training set and computing the PCA\n",
    "total_number_window_training = np.sum(n_win_files[random_indexes[0]]) + np.sum(n_win_files[random_indexes[1]]) + np.sum(n_win_files[random_indexes[2]]) + np.sum(n_win_files[random_indexes[3]])\n",
    "X_train = np.zeros((int(total_number_window_training), int(fv_len)))\n",
    "y_train = np.zeros(int(total_number_window_training))\n",
    "\n",
    "# we will use the indexes to load the mel spectrograms and compute the PCA\n",
    "index = 0\n",
    "for class_index in range (len(classnames)):\n",
    "    for audio_index in random_indexes[class_index]:\n",
    "        for window in range(int(n_win_files[class_index * 280 + audio_index])):\n",
    "            X_train[index, :] = np.load(folder_path + classnames[class_index] + str(audio_index) + \"_\" + str(window) + \".npy\")\n",
    "            y_train[index] = class_index\n",
    "            index += 1\n",
    "            \n",
    "# we will compute the PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=pca)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_train = X_train / np.linalg.norm(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicky\\AppData\\Local\\Temp\\ipykernel_8552\\3084020474.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_RF = results_RF._append({\"model\": \"Random Forest\", \"n_estimators\": n, \"max_depth\": d, \"min_samples_split\": s, \"accuracy\": acc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model                Random Forest\n",
      "n_estimators                    10\n",
      "max_depth                        5\n",
      "min_samples_split                2\n",
      "accuracy                  0.506209\n",
      "Name: 0, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    10\n",
      "max_depth                       10\n",
      "min_samples_split                5\n",
      "accuracy                  0.632123\n",
      "Name: 5, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    10\n",
      "max_depth                       10\n",
      "min_samples_split                5\n",
      "accuracy                  0.632123\n",
      "Name: 5, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    10\n",
      "max_depth                       10\n",
      "min_samples_split                5\n",
      "accuracy                  0.632123\n",
      "Name: 5, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    10\n",
      "max_depth                       10\n",
      "min_samples_split                5\n",
      "accuracy                  0.632123\n",
      "Name: 5, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    10\n",
      "max_depth                       10\n",
      "min_samples_split                5\n",
      "accuracy                  0.632123\n",
      "Name: 5, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    10\n",
      "max_depth                       10\n",
      "min_samples_split                5\n",
      "accuracy                  0.632123\n",
      "Name: 5, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    50\n",
      "max_depth                       20\n",
      "min_samples_split                5\n",
      "accuracy                  0.635278\n",
      "Name: 29, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    50\n",
      "max_depth                       50\n",
      "min_samples_split                2\n",
      "accuracy                  0.637646\n",
      "Name: 32, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    50\n",
      "max_depth                      100\n",
      "min_samples_split                5\n",
      "accuracy                  0.638432\n",
      "Name: 37, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    50\n",
      "max_depth                      100\n",
      "min_samples_split                5\n",
      "accuracy                  0.638432\n",
      "Name: 37, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                    50\n",
      "max_depth                      100\n",
      "min_samples_split                5\n",
      "accuracy                  0.638432\n",
      "Name: 37, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                   100\n",
      "max_depth                       20\n",
      "min_samples_split                2\n",
      "accuracy                  0.655251\n",
      "Name: 48, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                   100\n",
      "max_depth                       20\n",
      "min_samples_split                2\n",
      "accuracy                  0.655251\n",
      "Name: 48, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                   100\n",
      "max_depth                       20\n",
      "min_samples_split                2\n",
      "accuracy                  0.655251\n",
      "Name: 48, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                   100\n",
      "max_depth                       20\n",
      "min_samples_split                2\n",
      "accuracy                  0.655251\n",
      "Name: 48, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                   100\n",
      "max_depth                       20\n",
      "min_samples_split                2\n",
      "accuracy                  0.655251\n",
      "Name: 48, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                   100\n",
      "max_depth                       20\n",
      "min_samples_split                2\n",
      "accuracy                  0.655251\n",
      "Name: 48, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                   100\n",
      "max_depth                       20\n",
      "min_samples_split                2\n",
      "accuracy                  0.655251\n",
      "Name: 48, dtype: object\n",
      "model                Random Forest\n",
      "n_estimators                   100\n",
      "max_depth                       20\n",
      "min_samples_split                2\n",
      "accuracy                  0.655251\n",
      "Name: 48, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicky\\AppData\\Local\\Temp\\ipykernel_8552\\3084020474.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_SVM = results_SVM._append({\"model\": \"SVM\", \"kernel\": k, \"C\": c, \"gamma\": g, \"accuracy\": acc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model            SVM\n",
      "kernel           rbf\n",
      "C              0.001\n",
      "gamma          scale\n",
      "accuracy    0.477298\n",
      "Name: 0, dtype: object\n",
      "model            SVM\n",
      "kernel           rbf\n",
      "C              0.001\n",
      "gamma          scale\n",
      "accuracy    0.477298\n",
      "Name: 0, dtype: object\n",
      "model            SVM\n",
      "kernel           rbf\n",
      "C              0.001\n",
      "gamma          scale\n",
      "accuracy    0.477298\n",
      "Name: 0, dtype: object\n",
      "model            SVM\n",
      "kernel           rbf\n",
      "C             1000.0\n",
      "gamma             10\n",
      "accuracy    0.619546\n",
      "Name: 27, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "# we will test three models, CNN, SVM and Random Forest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# TO DO : implement the CNN model\n",
    "\n",
    "# 5-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Random Forest\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "max_depth = [5, 10, 20, 50, 100]\n",
    "min_samples_split = [2, 5, 10, 15]\n",
    "\n",
    "results_RF = pd.DataFrame(columns=[\"model\", \"n_estimators\", \"max_depth\", \"min_samples_split\", \"accuracy\"])\n",
    "\n",
    "for n in n_estimators:\n",
    "    for d in max_depth:\n",
    "        for s in min_samples_split:\n",
    "            clf = RandomForestClassifier(n_estimators=n, max_depth=d, min_samples_split=s)\n",
    "            acc = 0\n",
    "            for train_index, test_index in kf.split(X_train):\n",
    "                X_train_kf, X_test_kf = X_train[train_index], X_train[test_index]\n",
    "                y_train_kf, y_test_kf = y_train[train_index], y_train[test_index]\n",
    "                clf.fit(X_train_kf, y_train_kf)\n",
    "                acc += accuracy(y_test_kf, clf.predict(X_test_kf))\n",
    "            acc /= 5\n",
    "            results_RF = results_RF._append({\"model\": \"Random Forest\", \"n_estimators\": n, \"max_depth\": d, \"min_samples_split\": s, \"accuracy\": acc}, ignore_index=True)\n",
    "        print(results_RF.loc[results_RF[\"accuracy\"].idxmax()])\n",
    "        \n",
    "# save the results in a .csv file\n",
    "results_RF.to_csv(\"results_RF.csv\")\n",
    "\n",
    "\n",
    "# SVM\n",
    "kernel = [\"rbf\"]\n",
    "C = [0.001, 0.01, 0.1, 1000]\n",
    "gamma = [\"scale\", \"auto\", 0.1, 0.5, 1, 5, 10]\n",
    "\n",
    "# the results will be saved in a pandas dataframe\n",
    "results_SVM = pd.DataFrame(columns=[\"model\", \"kernel\", \"C\", \"gamma\", \"accuracy\"])\n",
    "\n",
    "for k in kernel:\n",
    "    for c in C:\n",
    "        for g in gamma:\n",
    "            clf = SVC(kernel=k, C=c, gamma=g)\n",
    "            acc = 0\n",
    "            for train_index, test_index in kf.split(X_train):\n",
    "                X_train_kf, X_test_kf = X_train[train_index], X_train[test_index]\n",
    "                y_train_kf, y_test_kf = y_train[train_index], y_train[test_index]\n",
    "                clf.fit(X_train_kf, y_train_kf)\n",
    "                acc += accuracy(y_test_kf, clf.predict(X_test_kf))\n",
    "            acc /= 5\n",
    "            results_SVM = results_SVM._append({\"model\": \"SVM\", \"kernel\": k, \"C\": c, \"gamma\": g, \"accuracy\": acc}, ignore_index=True)\n",
    "        print(results_SVM.loc[results_SVM[\"accuracy\"].idxmax()])\n",
    "\n",
    "# save the results in a .csv file\n",
    "results_SVM.to_csv(\"results_SVM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
